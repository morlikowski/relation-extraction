# Conclusions

I have presented and discussed a pipeline (Mintz et al. 2009) and a joint inference (Singh et al. 2013) approach to relation extraction. A comparison of both papers showed that the presented pipeline system is more feature-centric, has one-directional information flow, high precision and low recall, and does not model coreference, while the joint modeling example is more model-centric, has bi-directional information flow, balanced precision/recall and does model coreference. Both papers define relation extraction as a classification problem and use a log-linear classifier.

Concluding, I would like to remark, that in my view both papers managed to convey their respective
core idea in a convincing manner. Both distant supervision and (joint) graphical models address very general concerns in NLP, namely (automatically) generating training data and semantically clear modeling. However, I wonder about the range of applications of very complex probabilistic graphical models, because I got the impression that full joint modeling of three or more tasks is too computationally expensive (this was the first time that I have encountered graphical models, so I may not be fully aware of their use cases and characteristics). In regard to distant supervision, I wonder how a system will perform if it is not evaluated on the same kind of text that the knowledge base was constructed on (Wikipedia texts in this case).

An obvious extension on the discussed papers would be to test a combination of distant supervision and joint inference, learning a joint model (including coreference) on a large (but probably noisy) training set derived from a knowledge base.
I also wonder how the PGM joint model compares to neural network approaches, which are also able to perform tasks jointly and claim to reduce error propagation (e.g. Attardi 2015). I also wonder how their computational characteristics compare, as it seems to be common to train neural nets on GPU clusters for weeks. This comparison would also be interesting, as both presented approaches rely on careful feature engineering, while deep networks are often claimed to be less dependent on manual feature construction. In regard to automatic training data generation, the data programming approach (Ratner et al. 2016) is an interesting alternative/extension to distant supervision. In data programming, a user provides labeling functions that encode heuristics to generate a noisy training set. It is then tried to denoize the training set by assuming a generative model that has generated the noise and incorporating noise-awareness into a discriminative classifier.
